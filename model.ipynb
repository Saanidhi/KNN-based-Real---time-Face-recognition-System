{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2 #importing opencv library for video and image tools\n",
    "import numpy as np #NumPy is a general-purpose array-processing package.\n",
    "#It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
    "import os #provides function for interacting with operating system\n",
    "from IPython.display import display, clear_output #for various types of display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#haarcascade is an Algorithm which is used for detection of faces.It is comapritively slower as compared to LBHP Algorithm but has more accuracy.\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to find squareroot of the sum of squares of differences\n",
    "def dist(x1,x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to predict the label closest to their training data set using k nearest neighbours\n",
    "#X here contains the encoded face data \n",
    "#Y here stores the distance values of  the query point(detected face) and the training dataset\n",
    "#k defines the nearest neighbours\n",
    "def knn(X,Y,queryPoint,k=5): \n",
    "    vals = [] #vals here stores the distance values of  the query point(detected face) and the training dataset\n",
    "    m = X.shape[0]\n",
    "    for i in range(m):\n",
    "        d = dist(queryPoint,X[i]) \n",
    "        vals.append((d,Y[i])) \n",
    "    vals = sorted(vals) #sorting the vals array to determine the nearest/first k points\n",
    "     \n",
    "    vals = vals[:k]\n",
    "    vals = np.array(vals) #converting it to numpy array\n",
    "    new_vals = np.unique(vals[:,1],return_counts=True) #checking for unique values\n",
    "    index = new_vals[1].argmax() #returns the index of maximum element of a particular axis \n",
    "    pred = new_vals[0][index] #finding the predicted value using the index value\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to collect the training dataset\n",
    "def train():\n",
    "    cap = cv2.VideoCapture(0) #opening webcamera\n",
    "    skip = 0\n",
    "    photos_clicked = [] #array to store the photos of an individual\n",
    "    dataset_path = 'images/' #creating a folder to store images\n",
    "    file_name = input(\"Enter your name: \") #taking input from user\n",
    "    while True: \n",
    "        skip += 1\n",
    "        ret,frame = cap.read() \n",
    "        if ret == False:\n",
    "            continue\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #converting to gray image as open cv accepts gray images\n",
    "        faces = face_cascade.detectMultiScale(frame,1.3,5)  #using haarcascade algorithm to detect faces\n",
    "        faces = sorted(faces,key=lambda f:f[2]*f[3]) #sorting the faces based on their distance from the camera\n",
    "        # Pick the last face as it will be the largest\n",
    "        for face in faces[-1:]: \n",
    "            x,y,w,h = face\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2) #drawing a box around the face\n",
    "        # Extract the region of interest\n",
    "            offset = 10\n",
    "            face_section = gray_frame[y-offset:y+h+offset,x-offset:x+w+offset] #since we have to find the facial features we need to find region of interest, thereby cropping to get face encodings\n",
    "            face_section = cv2.resize(face_section,(100,100)) #resizing the face section\n",
    "            if skip%10 == 0: #after 10 frames the image is captured\n",
    "                photos_clicked.append(face_section) #they are added to the face_section array \n",
    "                print(len(photos_clicked))#prints the images being saved\n",
    "        cv2.imshow(\"Frame\",frame) #continuously showing the webcamera frame\n",
    "        key_pressed = cv2.waitKey(1) & 0xFF #to quit the entire process press \"q\" on the webcam screen\n",
    "        if key_pressed == ord('q'):\n",
    "            break\n",
    "\n",
    "    photos_clicked = np.asarray(photos_clicked) # Convert our face list array to a numpy array\n",
    "    photos_clicked = photos_clicked.reshape((photos_clicked.shape[0],-1)) #reshaping to suit the format of  numpy arrays\n",
    "    print(photos_clicked.shape)#print the number of photos saved\n",
    "\n",
    "    np.save(dataset_path+file_name+'.npy',photos_clicked) # Save this data to the file system\n",
    "    print(\"Images saved successfully!\")\n",
    "    cap.release()#releasing the captured webcam frame\n",
    "    cv2.destroyAllWindows() #destroying all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "def test():\n",
    "    cap = cv2.VideoCapture(0) #opening webcamera\n",
    "    \n",
    "    dataset_path = 'images/'\n",
    "    face_data = [] #array to store face_data\n",
    "    labels = [] #array to store labels mapping between id and names\n",
    "    names={} #array to store names \n",
    "    class_id = 0\n",
    "    for fx in os.listdir(dataset_path): #here fx stands for the files with each individual's images saved as npy\n",
    "        if fx.endswith('.npy'):\n",
    "            data_item = np.load(dataset_path+fx) #loading the file\n",
    "            face_data.append(data_item) #append in the face_data\n",
    "       \n",
    "            target = class_id*np.ones((data_item.shape[0],))  # Create labels for the class\n",
    "            labels.append(target) #adding to labels\n",
    "            names[class_id] = fx[:-4] #storing the names of individual\n",
    "            class_id += 1\n",
    "    face_data = np.concatenate(face_data,axis=0) #concatenating facedata of every individual \n",
    "    labels = np.concatenate(labels,axis=0)#concatenating label of every individual \n",
    "    test_point = np.zeros((100,100))  \n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        try:\n",
    "            ret,frame = cap.read() \n",
    "            if ret == False:\n",
    "                continue\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "            faces = sorted(faces,key=lambda f:f[2]*f[3])\n",
    "            # Pick the last face as it will be the largest\n",
    "            faces_in_frame=[]\n",
    "            for face in faces:\n",
    "                x,y,w,h = face\n",
    "                l=x\n",
    "                b=y\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "                # Extract the region of interest\n",
    "                offset = 10\n",
    "                face_section = gray_frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "                test_point = cv2.resize(face_section,(100,100))\n",
    "\n",
    "\n",
    "                y = test_point.reshape((-1,)) #query point ->the face for which we want to identify\n",
    "                label = knn(face_data,labels,y) #getting the label from the K-nn function\n",
    "                faces_in_frame.append(names[int(label)]) #appending all the faces in the frames\n",
    "                cv2.rectangle(frame, (l, b - 25), (l+w, b), (0, 0, 255), cv2.FILLED) #drawing a rectangle for displaying the name\n",
    "                cv2.putText(frame, names[int(label)], (l + 6, b - 6), font, 0.5, (255, 255, 255), 1) #putting text in the rectangle formed above\n",
    "\n",
    "            print(\"Hello \"+' '.join(faces_in_frame)) #displaying all the faces in frames\n",
    "            cv2.imshow(\"Frame\",frame) #showing the frame\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'): #waiting for the frame window\n",
    "                break\n",
    "        except:\n",
    "            cv2.imshow(\"Frame\",frame) #if no faces detected in the frame the error is caught in this section \n",
    "            print(\"Code not working\")\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            #cv2.waitKey(0) & 0xFF\n",
    "            \n",
    "\n",
    "    cap.release() #releasing the webcam\n",
    "    cv2.destroyAllWindows() #closing all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name: Saanidhi\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/opt/concourse/worker/volumes/live/d8bcd4d1-79b2-4aa5-797a-b95097f1118f/volume/opencv_1512680501887/work/modules/objdetect/src/cascadedetect.cpp:1698: error: (-215) !empty() in function detectMultiScale\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-93fd337a0d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5cbe6f054b3c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mgray_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#converting to gray image as open cv accepts gray images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#using haarcascade algorithm to detect faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sorting the faces based on their distance from the camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Pick the last face as it will be the largest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /opt/concourse/worker/volumes/live/d8bcd4d1-79b2-4aa5-797a-b95097f1118f/volume/opencv_1512680501887/work/modules/objdetect/src/cascadedetect.cpp:1698: error: (-215) !empty() in function detectMultiScale\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ea594c21b25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-6732fd5ab12c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m#array to store names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclass_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#here fx stands for the files with each individual's images saved as npy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdata_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#loading the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/'"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
